{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4c43f2-af29-45e4-ac82-9604185cab96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "arxiv_output_dir = './arxiv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e108ea63-0669-44c5-bf00-866bf2167ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_folders = os.listdir(arxiv_output_dir)\n",
    "date_folders.sort()\n",
    "\n",
    "if '.DS_Store' in date_folders:\n",
    "    date_folders.remove('.DS_Store')\n",
    "\n",
    "date_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fab34d0-d09c-408e-b355-18c77a59f857",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import os\n",
    "import gzip\n",
    "import tarfile\n",
    "import shutil\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from joblib_progress import joblib_progress\n",
    "\n",
    "def extract_mixed_gz(gz_path, output_folder):\n",
    "    \"\"\"\n",
    "    Extract a .gz file which could either contain a single file\n",
    "    or multiple files (e.g., in the form of a .tar).\n",
    "\n",
    "    Args:\n",
    "    - gz_path: Path to the .gz file.\n",
    "    - output_folder: Folder where the .gz file should be extracted to.\n",
    "\n",
    "    Returns:\n",
    "    None.\n",
    "    \"\"\"\n",
    "    # Create the output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # First, we decompress the gz file\n",
    "    decompressed_file_path = os.path.join(output_folder, os.path.basename(gz_path).replace('.gz', '') + '-temp')\n",
    "    with gzip.open(gz_path, 'rb') as f_in:\n",
    "        with open(decompressed_file_path, 'wb') as f_out:\n",
    "            shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "    extraction_folder = os.path.join(output_folder, os.path.basename(gz_path).replace('.gz', ''))\n",
    "    if not os.path.exists(extraction_folder):\n",
    "        os.makedirs(extraction_folder)\n",
    "\n",
    "    # Check if the decompressed result is a .tar file\n",
    "    if tarfile.is_tarfile(decompressed_file_path):\n",
    "        # Extract the tar file contents\n",
    "        with tarfile.open(decompressed_file_path, 'r') as tar:\n",
    "            tar.extractall(path=extraction_folder)\n",
    "        # Remove the temporary decompressed tar file\n",
    "        os.remove(decompressed_file_path)\n",
    "    else:\n",
    "        shutil.move(decompressed_file_path, os.path.join(extraction_folder, os.path.basename(gz_path).replace('.gz', '') + '.tex'))\n",
    "\n",
    "def extract_gz_to_tex(date_dir):\n",
    "    tex_output_dir = os.path.join(arxiv_output_dir, date_dir, 'tex')\n",
    "    os.makedirs(os.path.join(arxiv_output_dir, date_dir, 'src_invalid'), exist_ok=True)\n",
    "    pending_files = os.listdir(os.path.join(arxiv_output_dir, date_dir, 'src'))\n",
    "    pending_files.sort()\n",
    "\n",
    "    def inner_func(filename):\n",
    "        try:\n",
    "            src_path = os.path.join(arxiv_output_dir, date_dir, 'src', filename)\n",
    "            if not os.path.exists(src_path) or os.path.getsize(src_path) == 0:\n",
    "                return None\n",
    "            filename_stem = os.path.splitext(filename)[0]\n",
    "            filename_ext = os.path.splitext(filename)[1]\n",
    "            if filename_ext == '.pdf':\n",
    "                shutil.move(src_path, os.path.join(arxiv_output_dir, date_dir, 'src_invalid', filename))\n",
    "            elif filename_ext == '.gz':\n",
    "                extract_mixed_gz(src_path, tex_output_dir)\n",
    "            elif filename_ext == '.tex':\n",
    "                shutil.move(src_path, os.path.join(arxiv_output_dir, date_dir, 'tex', filename))\n",
    "        except Exception as e:\n",
    "            print('[ERROR]', str(e))\n",
    "        return filename\n",
    "    \n",
    "    with joblib_progress(\"Preprocessing...\", total=len(pending_files)):\n",
    "        Parallel(n_jobs=os.cpu_count(), pre_dispatch='1*n_jobs')(\n",
    "            delayed(inner_func)(f) for f in pending_files\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19ab8a2-8f90-4d9c-b064-2f062ddaeec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_dates = [\n",
    "    # '0001',\n",
    "    # '0002',\n",
    "    # '0003',\n",
    "    # '0004',\n",
    "    # '0005',\n",
    "    # '0006',\n",
    "    # '0007',\n",
    "    # '0008',\n",
    "    # '0009',\n",
    "    # '0010',\n",
    "    # '0011',\n",
    "    # '0012',\n",
    "    # '0501',\n",
    "    # '1001',\n",
    "    # '1501',\n",
    "    # '2001',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3c1058-704f-4214-a603-c1a584272329",
   "metadata": {},
   "outputs": [],
   "source": [
    "for date_folder_name in processing_dates:\n",
    "    extract_gz_to_tex(date_folder_name)\n",
    "    print(date_folder_name, len(os.listdir(os.path.join(arxiv_output_dir, date_folder_name, 'tex'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a759f291-0022-4089-a44a-ced8787f2468",
   "metadata": {},
   "source": [
    "# LaTeXML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a891aae1-a09d-40ce-8834-751ca679b5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import random  # Temp.\n",
    "from joblib import Parallel, delayed\n",
    "from joblib_progress import joblib_progress\n",
    "\n",
    "def convert_tex_to_html(datedir):\n",
    "    html_output_dir = os.path.join(arxiv_output_dir, datedir, 'html')\n",
    "    if not os.path.exists(html_output_dir):\n",
    "        os.mkdir(html_output_dir)\n",
    "    \n",
    "    log_output_dir = os.path.join(arxiv_output_dir, datedir, 'html_log')\n",
    "    if not os.path.exists(log_output_dir):\n",
    "        os.mkdir(log_output_dir)\n",
    "    \n",
    "    def inner_func(dirname):\n",
    "        dirpath = os.path.join(arxiv_output_dir, datedir, 'tex', dirname)\n",
    "        sub_files = os.listdir(dirpath)\n",
    "        tex_files = [file for file in sub_files if file.lower().endswith('.tex')]\n",
    "        if len(tex_files) == 0:\n",
    "            return 'Not found'\n",
    "        first_tex_filepath = os.path.join(dirpath, tex_files[0])\n",
    "        output_path = os.path.join(html_output_dir, dirname + '.html')\n",
    "        log_path = os.path.join(log_output_dir, dirname + '.log')\n",
    "    \n",
    "        if not os.path.exists(output_path):\n",
    "            command = ['latexmlc', '--dest=' + output_path, '--log=' + log_path, first_tex_filepath]\n",
    "            result = subprocess.run(' '.join(command), shell=True, stderr=subprocess.DEVNULL)\n",
    "\n",
    "        if not os.path.exists(output_path):\n",
    "            return 'Failed in LaTeXML'\n",
    "    \n",
    "        # If the output file is less than 5 KB, then we remove it.\n",
    "        if os.path.getsize(output_path) < 4000:\n",
    "            os.remove(output_path)\n",
    "            return 'Invalid size'\n",
    "        return 'OK'\n",
    "    \n",
    "    print(\"CPU:\", os.cpu_count())\n",
    "    pending_tex_files = os.listdir(os.path.join(arxiv_output_dir, datedir, 'tex'))\n",
    "    pending_tex_files = random.sample(pending_tex_files, 800)\n",
    "    pending_tex_files.sort()\n",
    "    \n",
    "    with joblib_progress(\"Processing...\", total=len(pending_tex_files)):\n",
    "        result = Parallel(n_jobs=os.cpu_count(), pre_dispatch='1*n_jobs')(\n",
    "            delayed(inner_func)(dirname) for dirname in pending_tex_files\n",
    "        )\n",
    "        \n",
    "    print('Done!')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d256ea1-2538-40ee-bb40-8c62cc8548d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(date_folder_name):\n",
    "    res_curr_date = convert_tex_to_html(date_folder_name)\n",
    "    print(date_folder_name, sum([i == 'OK' for i in res_curr_date]), sum([i != 'OK' for i in res_curr_date]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9ef1d8-70b8-48ff-bef2-55b2de5d131d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess('0001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83110a52-45ed-4d55-8d95-9873e7915fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess('0002')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ecf81d-2fc1-4e2f-ac26-0d82c31670e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess('0003')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aafe20f-eb99-466f-9dc9-1e7a8c154923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess('0004')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718414a2-680c-4789-bfc5-a6d65d67a1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess('0005')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4843772e-d7ec-43b8-896e-599da07b6c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess('0006')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661c9359-76d8-4fc4-a73e-a1e81b08b99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess('0007')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c598f1d3-5908-44c3-8d48-d0a13852ddb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess('0008')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9263a4fa-7c06-4d80-842a-b304c2bb2abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess('0009')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3670320b-d45d-4035-8ba9-ad14c583751d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess('0010')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbf6c12-4eeb-45ec-b098-fe3bdde5e85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess('0011')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d626f8ef-df22-4da9-967f-00d42558ee05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess('0012')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9756644f-b582-4a0f-8479-68eb55172853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess('0501')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f4c14f-5bbd-4ee0-b6d2-ca462a6996ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess('1001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06c16bf-70ac-44c2-83ae-eb0f57c135d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess('1501')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108373a3-b885-4002-b869-04be0fccc482",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# preprocess('2001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8481fcb7-f4d8-446b-96df-dff62c986d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block is used to clean up unnecessary logs in the working dir.\n",
    "\n",
    "# import glob\n",
    "# import os\n",
    "\n",
    "# # Find all .log files in the current directory\n",
    "# log_files = glob.glob('./*.log')\n",
    "\n",
    "# # Remove each file\n",
    "# for file in log_files:\n",
    "#     os.remove(file)\n",
    "#     print(f\"Removed {file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
